{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f7c64d",
   "metadata": {},
   "source": [
    "Kaggle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4919cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b795e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:\\\\Users\\\\varad\\\\Desktop\\\\Technical_Seminar\\\\kaggle_datasets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57816019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5e03e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(df.loc[:,'kernels':'upvotes'].columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c87f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199383c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df['title']+\" \"+df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56eb56b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c779b9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varad\\AppData\\Local\\Temp\\ipykernel_25556\\281546249.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text']=df[\"text\"].str.replace(\"[^a-zA-z0-9]\",\" \")\n"
     ]
    }
   ],
   "source": [
    "df['text']=df['text'].apply(lambda x: x.lower())\n",
    "df['text']=df[\"text\"].str.replace(\"[^a-zA-z0-9]\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3c776cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(text,noise):\n",
    "    r=re.findall(noise,text)\n",
    "    for i in r:\n",
    "        text=re.sub(i,\"\",text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca65b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=np.vectorize(remove_noise)(df['text'],\"@[\\w]*\")\n",
    "df['text']=df['text'].apply(lambda x:re.sub(r\"http\\S+\\www\\S+|https\\S+\", \"\",x,flags=re.MULTILINE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce892933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e40a756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization\n",
    "df['text']=df['text'].apply(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba594144",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=['for','me', 'the', 'had', 'if', 'be', 'than', 'weren', 'after', 'are', 'because', 'ourselves', 'below', 'is', 'now', 'with', 'aren', 'here', 'nor', 'hadn', 'that', 'shan', 'all', 'yourselves', 'their', 'haven', 'herself', 'who', 'am', 'both', 'just', 'when', 'above', \"shouldn't\", 's', 'down', \"shan't\", 'doesn', 'to', 'through', \"you're\", 'from', 'myself', \"should've\", 'y', 'her', \"weren't\", 'until', 'then', 'own', 'wasn', 'we', 'its', 'at', 'how', 'under', 'other', 'are', 'why', 'of', 'can', 'which', 'so']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e47cc527",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in df['text']:\n",
    "    for word in text:\n",
    "        if word in stopwords:\n",
    "            text.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6ce86fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c96076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df['text'].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0eeede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text'].head()\n",
    "def callfun():\n",
    "    search_list = sorted(list(enumerate(similarity[8036])),reverse=True,key=lambda x:x[1])[1:12]\n",
    "    matched_dataset=[]\n",
    "    j=0\n",
    "    for i in (search_list):\n",
    "        if(search_list[j][1]==0):\n",
    "            break;\n",
    "        j=j+1\n",
    "        results=[]\n",
    "        results.append(df.iloc[i[0]]['title'])\n",
    "        results.append((df.iloc[i[0]]['url']))\n",
    "\n",
    "        matched_dataset.append(results)\n",
    "\n",
    "    result_datasets=pd.DataFrame(matched_dataset,columns=['Dataset','URL'])\n",
    "\n",
    "\n",
    "    if(len(result_datasets)>0):\n",
    "        print(result_datasets.to_markdown())\n",
    "    else:\n",
    "        print(\"No result found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8c32dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "    # settings that you use for count vectorizer will go here \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "378bbcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Dataset Here :datasets for sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varad\\AppData\\Local\\Temp\\ipykernel_25556\\2151333819.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  temp=df.append(dataset_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Dataset                               | URL                                                                    |\n",
      "|---:|:--------------------------------------|:-----------------------------------------------------------------------|\n",
      "|  0 | Sentiment Analysis                    | https://www.kaggle.com/varunkashyapks/sentiment-analysis               |\n",
      "|  1 | Sentiment Analysis Dataset            | https://www.kaggle.com/sonaam1234/sentimentdata                        |\n",
      "|  2 | movie-sentiment-analysis              | https://www.kaggle.com/yuhaowang/moviesentimentanalysis                |\n",
      "|  3 | IMDB Sentiment Analysis               | https://www.kaggle.com/kaushik3497/imdb-sentiment-analysis             |\n",
      "|  4 | Twitter Sentiment Analysis            | https://www.kaggle.com/nikhilparihar/twitter-sentiment-analysis        |\n",
      "|  5 | just for competition                  | https://www.kaggle.com/pavetr/portosegurotemp                          |\n",
      "|  6 | Opinion Lexicon                       | https://www.kaggle.com/nltkdata/opinion-lexicon                        |\n",
      "|  7 | Rare diseases - Sentiment analysis    | https://www.kaggle.com/natt77/rare-diseases-sentimient-analysis        |\n",
      "|  8 | Driver                                | https://www.kaggle.com/naveenbanda/driver                              |\n",
      "|  9 | Sentiment Labelled Sentences Data Set | https://www.kaggle.com/rahulin05/sentiment-labelled-sentences-data-set |\n",
      "| 10 | Pros and Cons                         | https://www.kaggle.com/nltkdata/pros-an-cons                           |\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True) \n",
    "\n",
    "name=input(\"Search Dataset Here :\")\n",
    "\n",
    "dataset_name=pd.DataFrame({'title':\" \",\"description\":\" \",'url':' ','owner':' ','text':name},index=[8036])\n",
    "\n",
    "temp=df.append(dataset_name)\n",
    "\n",
    "temp=temp['text']\n",
    "\n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(temp)\n",
    "\n",
    "similarity=cosine_similarity(tfidf_vectorizer_vectors)\n",
    "\n",
    "callfun()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b258d3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f7196a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af24983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
